# -*- coding: utf-8 -*-
"""Submission : Predictive Analytics

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vHhnsd-t8UlqQqt_i21TPFpqL5Svnvvq

# Predictive Analytics : Emisi CO2 oleh Kendaraan

![Image Emission C02](https://png.pngtree.com/png-clipart/20230925/original/pngtree-the-vehicle-emits-copious-amounts-of-co2-a-harmful-greenhouse-gas-png-image_12784556.png)

## Business Understanding

### Problem Statements

Rumusan masalah dari masalah latar belakang diatas adalah :
- Dari berbagai fitur yang ada, fitur mana yang paling berpengaruh terhadap emisi CO2 yang dihasilkan oleh kendaraan?
- Bagaimana mengetahui banyak emisi CO2 yang dihasilkan oleh kendaraan berdasarkan riwayat dari fitur-fitur yang ada?

### Goals

tujuan untuk menyelesaikan permasalahan diatas adalah:
- Mengetahui fitur yang paling berkorelasi dengan emisi CO2 yang dihasilkan oleh kendaraan.
- Membuat model machine learning yang dapat memprediksi seberapa banyak emisi CO2 yang dihasilkan oleh kendaraan secara akurat berdasarkan fitur-fitur yang ada.

### Solution statements
- Melakukan analisis pada data untuk memahami fitur-fitur yang mempengaruhi emisi CO2, dengan menerapkan teknik visualisasi data guna mengetahui korelasi antar fitur dan memahami hubungan antara data target (label) dan fitur lainnya.
- Menggunakan berbagai algoritma machine learning untuk membandingkan performa model, dengan tujuan mendapatkan model atau algoritma yang memiliki akurasi prediksi tertinggi dalam memperkirakan jumlah emisi CO2 yang dihasilkan oleh kendaraan.-

### Metodologi

Prediksi emisi CO2 kendaraan adalah tujuan yang ingin dicapai. Seperti yang kita ketahui, emisi CO2 merupakan variabel kontinu. Dalam predictive analytics, ketika membuat prediksi variabel kontinu, artinya Anda sedang menyelesaikan permasalahan regresi. Oleh karena itu, metodologi pada proyek ini adalah membangun model regresi dengan emisi CO2 kendaraan sebagai target.

### Metrik

Metrik yang digunakan untuk mengevaluasi seberapa baik model regresi dalam kasus prediksi variabel kontinu, seperti emisi CO2 kendaraan, antara lain adalah Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), dan R-squared (R²). Metrik-metrik ini membantu mengukur seberapa akurat prediksi model terhadap nilai aktual. MAE mengukur rata-rata kesalahan absolut, MSE memberikan penalti lebih besar untuk kesalahan yang lebih besar, RMSE menunjukkan seberapa besar penyimpangan prediksi secara keseluruhan, dan R² mengukur proporsi variabilitas yang dapat dijelaskan oleh model.

## Data Understanding

adalah tahap dalam proses analisis data yang bertujuan untuk memahami dataset secara mendalam sebelum melakukan analisis lebih lanjut.

### Data Loading

Data Loading merupakan tahap untuk memuat dataset yang akan digunakan agar dataset lebih mudah dipahami.

<br>


**Informasi Datasets**


| Jenis | Keterangan |
| ------ | ------ |
| Title | CO2 Emission by Vehicles |
| Source | [Kaggle](https://www.kaggle.com/datasets/debajyotipodder/co2-emission-by-vehicles) |
| Owner | [Debajyoti Podder](https://www.kaggle.com/debajyotipodder) |
| License | Database: Open Database, Contents |
| Visibility | Publik |
| Tags | Business, Earth and Nature, Computer Science, Automobiles and Vehicles, Regression, Environment, Linear Regression, Pollution |
| Usability | 10.00 |
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

!pip install gdown

!gdown --folder https://drive.google.com/drive/folders/1LezwKP2AjtAj0DT5iuaGpo6r7HuC8k2_

path = '/content/Dataset CO2 Emissions/CO2 Emissions_Canada.csv'
df = pd.read_csv(path)
df

"""Output kode di atas memberikan informasi sebagai berikut:

Ada **7385 baris** dalam dataset dan terdapat **12 kolom** yaitu.

### Exploratory Data Analysis - Deskripsi Variabel

Berdasarkan informasi dari Kaggle, variabel-variabel pada **CO2 Emission by Vehicles** dataset adalah sebagai berikut: adalah sebagai berikut:

<br>

- **Make** : Perusahaan yang membuat kendaraan
- **Model** : Model dari kendaraan
- **Vehicle Class** : Kelas dari kendaraan berdasarkan utilitas, kapasitas dan berat
- **Engine Size (L)** : Ukuran dari mesin dalam satuan liter (L)
- **Cylinders** : Jumlah silinder kendaraan (ruang naiknya piston)
- **Transmission** : Tipe transmisi dengan jumlah gigi kendaraan
  - A = Otomatis
  - AM = Manual Otomatis
  - AS = Otomatis dengan pilihan shift
  - AV = Variabel kontinu
  - M = Manual
  - X = Angka dari gigi
- **Fuel Type** : Tipe bahan bakar
  - X = Bensin Reguler
  - Z = Bensin Premium
  - D = Disel
  - E = Ethanol (E85)
  - N = Gas Natural
- **Fuel Consumption City (L/100 km)** : Jumlah konsumsi bahan bakar dijalanan kota dalam satuan (L/100 km)
- **Fuel Consumption City (L/100 km)** : Jumlah konsumsi bahan bakar dijalanan raya dalam satuan (L/100 km)
- **Fuel Consumption Comb (L/100 km)** : Jumlah konsumsi bahan bakar (55% kota. 45% jalan raya) dalam satuan (L/100 km)
- **CO2 Emissions(g/km)** : Emisi knalpot karbon dioksida dalam gram/kilometer (g/km) dari gabungan berkendara pada jalanan kota dan jalan raya.
"""

df.info()

"""Dari Output diketahui bahaw:

- Terdapat **4 kolom** dengan tipe data **float64**.
- Terdapat **3 kolom** numerik dengan tipe data **int64**.
- Terdapat **5 kolom** dengan tipe data **object**.
"""

df = df.drop(['Make', 'Model', 'Vehicle Class'], axis = 1)

"""Kode diatas untuk menghapus beberapa fitur yang tidak penting yaitu:

- Make: Fitur ini dihapus karena hanya berisi informasi mengenai nama perusahaan pembuat kendaraan.
- Model: Fitur ini dihapus karena hanya menjelaskan model dari kendaraan tersebut.
- Vehicle Class: Fitur ini dihapus karena hanya mengkategorikan model berdasarkan utilitas, kapasitas, dan dimensi kursi penumpang.
"""

df.describe()

"""Fungsi `describe()` memberikan informasi statistik pada masing-masing kolom, antara lain:

- `Count` adalah jumlah sampel pada data.
- `Mean` adalah nilai rata-rata.
- `Std` adalah standar deviasi.
- `Min` yaitu nilai minimum setiap kolom.
- `25%` adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- `50%` adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
-` 75%` adalah kuartil ketiga.
- `Max` adalah nilai maksimum.
"""

df.shape

"""Dari Output diatas didapat informasi:
<br>

| Jumlah Baris | Jumlah Kolom |
| ------ | ------ |
| 7385 | 9 |


<br>

### Exploratory Data Analysis - Menangani Missing Value dan Outliers
"""

df.duplicated().sum()

df_cleaned = df.drop_duplicates()

"""setelah dicek terdapat 2819 data yang duplicated yang kemudian kita hapus"""

df_cleaned.isnull().sum()

"""dari output diatas didapati bahwa tidak terdapat missing value pada dataset."""

engine = (df_cleaned['Engine Size(L)'] == 0).sum()
cylinders = (df_cleaned['Cylinders'] == 0).sum()
transmission = (df_cleaned['Transmission'] == 0).sum()
ft = (df_cleaned['Fuel Type'] == 0).sum()
fcc = (df_cleaned['Fuel Consumption City (L/100 km)'] == 0).sum()
fch = (df_cleaned['Fuel Consumption Hwy (L/100 km)'] == 0).sum()
fccl = (df_cleaned['Fuel Consumption Comb (L/100 km)'] == 0).sum()
fccm = (df_cleaned['Fuel Consumption Comb (mpg)'] == 0).sum()
emission = (df_cleaned['CO2 Emissions(g/km)'] == 0).sum()


print("Nilai 0 di kolom Engine Size(L) ada: ", engine)
print("Nilai 0 di kolom Cylinders: ", cylinders)
print("Nilai 0 di kolom Transmission ada: ", transmission)
print("Nilai 0 di kolom Fuel Type ada: ", ft)
print("Nilai 0 di kolom Fuel Consumption City (L/100 km) ada: ", fcc)
print("Nilai 0 di kolom Fuel Consumption Hwy (L/100 km) ada: ", fch)
print("Nilai 0 di kolom Fuel Consumption Comb (L/100 km) ada: ", fccl)
print("Nilai 0 di kolom Fuel Consumption Comb (mpg) ada: ", fccm)
print("Nilai 0 di kolom CO2 Emissions(g/km) ada: ", emission)

"""setelah dicek untuk setiap kolum yg dipilih tidak terdapat nilai 0."""

df_cleaned.describe()

df_cleaned.shape

"""total data menjadi 4566 baris

**Menangani Outliers**

menangani outliers dengan IQR Method
"""

#Cek data outlier
numerical_feature = ['Engine Size(L)', 'Cylinders', 'Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)', 'Fuel Consumption Comb (mpg)', 'CO2 Emissions(g/km)']
categorical_feature = ['Transmission', 'Fuel Type']

for num in numerical_feature:
    plt.figure(figsize=(10, 5))
    sns.boxplot(data=df_cleaned, x=num, color='skyblue')
    plt.title(f'Boxplot of {num}')
    plt.xlabel(num)
    plt.show()

selected_cols = df_cleaned[numerical_feature]

Q1 = selected_cols.quantile(0.25)
Q3 = selected_cols.quantile(0.75)
IQR = Q3 - Q1

df_filtered = df_cleaned[~((selected_cols < (Q1 - 1.5 * IQR)) | (selected_cols > (Q3 + 1.5 * IQR))).any(axis=1)]

df_filtered.shape

"""dataset kini menjadi **4107 baris** setelah penghapusan **outlier**

### Exploratory Data Analysis - Univariate Analysis
"""

feature = categorical_feature[0]
count = df_filtered[feature].value_counts()

#Categorical
percent = 100 * df_filtered[feature].value_counts(normalize = True)
df = pd.DataFrame({'Jumlah sample' : count, 'Persentase' : percent.round(1)})
print(df)

plt.figure(figsize=(15, 5))
sns.countplot(x=feature, data=df_filtered, order=df_filtered['Transmission'].value_counts().index, palette='Set3')  # Ganti 'skyblue' dengan warna yang diinginkan
plt.title('Count of ' + feature)
plt.xlabel(feature)
plt.ylabel('Count')
plt.show()

"""Terdapat 27 kategori fitur untuk transmisi yang dapat disimpulkan sebagai berikut:

- **Transmisi AS (Otomatis dengan pilihan shift)**: sebanyak 45.0% dari total sampel.
- **Transmisi A (Otomatis)**: sebanyak 19.2% dari total sampel.
- **Transmisi M (Manual)**: sebanyak 12.3% dari total sampel.
- **Transmisi AM (Manual Otomatis)**: sebanyak 7.7% dari total sampel.
- **Transmisi AV (Variabel kontinu)**: sebanyak 8.3% dari total sampel.

Dapat disimpulkan bahwa hampir setengah dari total kendaraan menggunakan tipe transmisi AS (Otomatis dengan pilihan shift), dengan proporsi mencapai 45.0%.
"""

feature = categorical_feature[1]
count = df_cleaned[feature].value_counts()
percent = 100*df_cleaned[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)

plt.figure(figsize=(15, 5))
sns.countplot(x=feature, data=df_filtered, order=df_filtered['Fuel Type'].value_counts().index, palette='Set3')
plt.title('Count of ' + feature)
plt.xlabel(feature)
plt.ylabel('Count')
plt.show()

"""Pada jenis bahan bakar, terdapat lima kategori, yaitu **X, Z, E, D,** dan **N**. Dapat disimpulkan bahwa sebagian besar kendaraan menggunakan bahan bakar jenis **X** dan **Z**, yaitu **Bensin Reguler** dan **Bensin Premium**, yang memiliki persentase mencapai **92,6%**.

**Numerical Features**

Selanjutnya, untuk fitur numerik, kita akan melihat histogram masing-masing fiturnya.
"""

df_filtered.hist(bins=50, figsize=(20,15), color= 'skyblue')
plt.show()

"""Pada histogram di atas, khususnya pada fitur Emisi CO2 (g/km), dapat disimpulkan bahwa:

- Peningkatan emisi CO2 sejalan dengan meningkatnya jumlah sampel. Hal ini terlihat dari histogram fitur "Emisi CO2" yang menunjukkan peningkatan seiring bertambahnya sampel.
- Kadar emisi CO2 yang dihasilkan mencapai dua kali lipat dari batas normal, yaitu 522 g/km.
- Setengah dari kadar emisi CO2 berada dalam rentang 246 g/km.
Mayoritas kadar emisi CO2 terletak pada kuartil pertama hingga kuartil ketiga.
- Distribusi emisi CO2 cenderung miring ke kanan (left-skewed), yang menunjukkan bahwa nilai median (nilai tengah) berada di kuartil ketiga dan lebih tinggi daripada nilai rata-rata.

### Exploratory Data Analysis - Multivariate Analysis

Categorical Features
"""

cat_features = df_filtered.select_dtypes(include='object').columns.to_list()

for col in cat_features:
    sns.catplot(x=col, y="CO2 Emissions(g/km)", kind="bar", dodge=False, height=4, aspect=3, data=df_filtered, hue=col, palette="Set2", legend=False)
    plt.title("Rata-rata CO2 Emissions(g/km) terhadap - {}".format(col))
    plt.show()

"""Pada visualisasi terhadap fitur kategori, dapat disimpulkan:

- Rentang CO2 Emission pada tiap tipe transmission berkisar pada 140 - 300, dapat dilihat distribusi data tidak mengalami penurunan maupun peningkatan yang membuktikan kalau fitur transmission memiliki dampak kecil terhadap CO2 Emission
- Rentang CO2 Emission pada Fuel Type berada diatas 200 sampai dengan 250, dimana tiap Fuel Type memiliki kemiripan dan rentang yang tidak terlalu berselisih jauh yang membuktikan kalau fitur Fuel Type memiliki dampat kecil terhadap CO2 Emission.

**Numerical Features**

Untuk mengamati hubungan antara fitur numerik, kita akan menggunakan fungsi pairplot(). Kita juga akan mengobservasi korelasi antara fitur numerik dengan fitur target menggunakan fungsi corr().
"""

sns.pairplot(df_filtered, diag_kind = 'kde', height=3)

"""Pada visualisasi diatas dapat disimpulkan:

- Engine Size (L) vs CO2 Emissions (g/km): Terlihat hubungan linear yang kuat antara ukuran mesin dan emisi CO2. Semakin besar ukuran mesin, semakin tinggi pula emisi CO2 yang dihasilkan. Ini menunjukkan bahwa fitur ukuran mesin memiliki pengaruh signifikan terhadap emisi CO2.

- Fuel Consumption City (L/100 km) vs CO2 Emissions (g/km): Ada korelasi yang jelas antara konsumsi bahan bakar di dalam kota dan emisi CO2. Semakin tinggi konsumsi bahan bakar di dalam kota, semakin tinggi pula emisi CO2.

- Fuel Consumption Hwy (L/100 km) vs CO2 Emissions (g/km): Sama halnya dengan konsumsi bahan bakar di jalan raya, hubungan linear juga terlihat di sini, dengan peningkatan konsumsi bahan bakar di jalan raya berbanding lurus dengan peningkatan emisi CO2.

- Fuel Consumption Comb (L/100 km) vs CO2 Emissions (g/km): Konsumsi bahan bakar gabungan juga memiliki korelasi positif dengan emisi CO2. Semakin tinggi konsumsi bahan bakar, semakin tinggi emisi CO2 yang dihasilkan.

- Fuel Consumption Comb (mpg) vs CO2 Emissions (g/km): Dalam grafik ini, terlihat bahwa semakin tinggi (mpg), semakin rendah emisi CO2. Ini menunjukkan bahwa efisiensi bahan bakar yang lebih baik (mpg lebih tinggi) menghasilkan emisi CO2 yang lebih rendah.
"""

plt.figure(figsize=(10, 8))
correlation_matrix = df_filtered[numerical_feature].corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Berdasarkan matriks korelasi untuk fitur numerik yang ditampilkan:

- Engine Size (L) memiliki korelasi yang kuat dengan CO2 Emissions (g/km) sebesar 0.82. Ini menunjukkan bahwa semakin besar ukuran mesin, semakin tinggi emisi CO2. Selain itu, Engine Size (L) juga memiliki korelasi tinggi dengan jumlah Cylinders (0.94), yang cukup logis mengingat mesin yang lebih besar cenderung memiliki lebih banyak silinder.

- Cylinders juga memiliki korelasi yang tinggi dengan CO2 Emissions (g/km) (0.8), menunjukkan bahwa kendaraan dengan lebih banyak silinder cenderung menghasilkan lebih banyak emisi.

- Fuel Consumption (L/100 km), baik dalam kota (City), di jalan raya (Hwy), maupun gabungan (Comb), semuanya memiliki korelasi sangat tinggi dengan CO2 Emissions (g/km), masing-masing 0.91, 0.9, dan 0.92. Ini mengindikasikan bahwa konsumsi bahan bakar merupakan faktor utama yang mempengaruhi emisi CO2.

- Sebaliknya, Fuel Consumption Comb (mpg) menunjukkan korelasi negatif yang kuat dengan CO2 Emissions (g/km) (-0.92). Ini berarti bahwa kendaraan dengan efisiensi bahan bakar yang lebih tinggi (mpg lebih tinggi) menghasilkan emisi CO2 yang lebih rendah, sesuai dengan ekspektasi.

- Korelasi antara Fuel Consumption City (L/100 km) dan Fuel Consumption Hwy (L/100 km) adalah sangat tinggi (0.94), begitu juga antara keduanya dengan Fuel Consumption Comb (L/100 km) yang masing-masing 0.99 dan 0.97. Ini menunjukkan bahwa ketiga variabel ini sangat terkait satu sama lain dan cenderung memberikan informasi yang serupa.

## Data Preparation

Teknik Data preparation yang dilakukan terdiri dari:

- Label encoding
- OneHot encoding
- Reduksi dimensi dengan PCA
- Train-test-split data

### Encoding Fitur Kategori
"""

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()

df_filtered['Transmission'] = label_encoder.fit_transform(df_filtered['Transmission'])

df_filtered.head(25)

"""fitur Transmission akan diubah menggunakan LabelEncoder."""

from sklearn.preprocessing import  OneHotEncoder
df_final = pd.concat([df_filtered, pd.get_dummies(df_filtered['Fuel Type'], prefix='Fuel Type')],axis=1)
df_final.head()

"""fitur Fuel Type diubah menggunakan OneHotEncoder.

### Reduksi Dimensi dengan PCA

Teknik reduksi (pengurangan) dimensi adalah prosedur yang mengurangi jumlah fitur dengan tetap mempertahankan informasi pada data. Teknik pengurangan dimensi yang paling populer adalah Principal Component Analysis atau disingkat menjadi PCA. Ia adalah teknik untuk mereduksi dimensi, mengekstraksi fitur, dan mentransformasi data dari “n-dimensional space” ke dalam sistem berkoordinat baru dengan dimensi m, di mana m lebih kecil dari n.
"""

sns.pairplot(df_final[['Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)']],
             plot_kws={"s": 3}, height=3)

plt.tight_layout()
plt.show()

"""pada pairplot diatas terlihat kalau ketiga feature yaitu Fuel Consumption City (L/100 km), Fuel Consumption Hwy (L/100 km) dan Fuel Consumption Comb (L/100 km) memiliki korelasi yang cukup tinggi sehingga dapat dilakukan proses reduksi dimensi"""

from sklearn.decomposition import PCA

pca = PCA(n_components=3, random_state=123)
pca.fit(df_final[['Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)']])
princ_comp = pca.transform(df_final[['Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)']])

pca.explained_variance_ratio_.round(3)

pca = PCA(n_components = 1, random_state = 50)
pca.fit(df_final[['Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)']])
df_final['Fuel Consumption'] = pca.transform(df_final.loc[:, ('Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)')]).flatten()
df_final.drop(['Fuel Type','Fuel Consumption City (L/100 km)', 'Fuel Consumption Hwy (L/100 km)', 'Fuel Consumption Comb (L/100 km)'], axis = 1, inplace = True)

"""Setelah diketahui ketiga fitur tersebut berkorelasi dilakukan reduksi dimensi dengan PCA, membuat fitur baru yaitu Fuel Consumption untuk menggantikan ketiga fitur tersebut."""

df_final.head()

"""### Train-Test-Split"""

from sklearn.model_selection import train_test_split

X = df_final.drop(["CO2 Emissions(g/km)"],axis =1)
y = df_final["CO2 Emissions(g/km)"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)

"""memisahkan antara fitur dan label. Variabel x digunakan untuk menyimpan fitur sedangkan variabel y digunakan untuk menyimpan label yaitu CO2 Emissions (g/km).

- Selanjutnya, dilakukan train-test-split dengan pembagian data sebesar 90:10 antara data latih (train) dan data uji (test).
"""

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""### Standarisasi"""

from sklearn.preprocessing import MinMaxScaler

numerical_features = ['Engine Size(L)', 'Cylinders', 'Transmission', 'Fuel Consumption Comb (mpg)']
scaler = MinMaxScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(6)

"""Algoritma machine learning memiliki performa lebih baik dan konvergen lebih cepat ketika dimodelkan pada data dengan skala relatif sama atau mendekati distribusi normal. Proses scaling dan standarisasi membantu untuk membuat fitur data menjadi bentuk yang lebih mudah diolah oleh algoritma.

- Nantinya standarisasi MinMaxScaler menghasilkan distribusi data yang ada pada rentang 0 dan 1.

## Model Development

Pada tahapan model development ini algoritma machine learning yang digunakan terdiri dari:

- Decision Tree Regression
- KNN
- Linear Regression
- SVR
- Random Forest
- Boosting

### Model Development dengan K-Nearest Neighbor
"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['DecisionTree', 'KNN', 'LinearRegression', 'SVR', 'RF', 'boosting_RF'])

"""### Model Development dengan Decision Tree Regressor"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error

dt_regressor = DecisionTreeRegressor(min_samples_leaf = 1, min_samples_split = 2, max_depth = None, max_features = None, random_state = None)
dt_regressor.fit(X_train, y_train)

models.loc['train_mse', 'DecisionTree'] = mean_squared_error(y_true=y_train, y_pred=dt_regressor.predict(X_train))

"""DecisionTreeRegressor dengan parameter sebagai berikut:

  - max_depth = None :  Kedalaman maksimum pohon (default: None, yang berarti pohon akan terus tumbuh hingga semua daun murni atau hingga semua daun memiliki kurang dari min_samples_split sampel).

  - min_samples_split: Jumlah minimum sampel yang diperlukan untuk membagi simpul (default: 2).

  - min_samples_leaf: Jumlah minimum sampel yang diperlukan untuk berada di simpul daun (default: 1).

  - max_features: Jumlah maksimum fitur yang dipertimbangkan untuk pemisahan terbaik (default: None, yang berarti semua fitur dipertimbangkan).

  - random_state: Menentukan generator bilangan acak untuk memastikan hasil yang dapat direproduksi (default: None).

### Model Development dengan K-Nearest Neighbor (KNN)
"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse','KNN'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""- K-Nearest Neighbor dengan parameter sebagai berikut:

  - n_neighbors = 10 : jumlah tetangga yang digunakan untuk mengukur jarak

### Model Development dengan Linear Regression
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

linear_regressor = LinearRegression(fit_intercept = True, n_jobs = None, positive = False)
linear_regressor.fit(X_train, y_train)

models.loc['train_mse', 'LinearRegression'] = mean_squared_error(y_true=y_train, y_pred=linear_regressor.predict(X_train))

"""- LinearRegression dengan parameter sebagai berikut:

  - fit_intercept=True: Menentukan apakah model akan menghitung intercept (konstanta) dari regresi. Jika diatur ke True, model akan memasukkan intercept dalam perhitungan.

  - n_jobs=None: Menentukan jumlah pekerjaan paralel untuk menghitung (fit) model. None berarti menggunakan satu inti; jika diatur ke -1, akan menggunakan semua inti yang tersedia.

  - positive=False: Menentukan apakah koefisien regresi harus dibatasi menjadi nilai positif. Jika diatur ke True, model akan memaksa semua koefisien menjadi non-negatif.

### Model Development dengan Support Vector Regression (SVR)
"""

from sklearn.svm import SVR
svr = SVR(C = 1.0, epsilon = 0.1, gamma = 'scale', kernel = 'rbf')
svr.fit(X_train, y_train)

models.loc['train_mse', 'SVR'] = mean_squared_error(y_true=y_train, y_pred=svr.predict(X_train))

"""- Support Vector Regression dengan parameter sebagai berikut:

  - C=1.0: Parameter regulasi yang mengontrol trade-off antara minimisasi kesalahan pelatihan dan kompleksitas model. Nilai yang lebih tinggi akan menghasilkan model yang lebih kompleks, sedangkan nilai yang lebih rendah dapat menghasilkan model yang lebih sederhana.

  - epsilon=0.1: Menentukan margin toleransi di sekitar garis prediksi. Ini berarti bahwa kesalahan di dalam margin ini tidak akan dikenakan penalti. Dengan kata lain, model tidak akan berusaha untuk memperbaiki kesalahan di dalam radius epsilon.

  - gamma='scale': Mengontrol pengaruh titik pelatihan individu. Jika diatur ke 'scale', gamma akan dihitung sebagai 1 / (n_features * X.var()). Ini menentukan seberapa jauh pengaruh dari titik data.

  - kernel='rbf': Menggunakan kernel Radial Basis Function (RBF) untuk mengubah data menjadi dimensi yang lebih tinggi, memungkinkan pemisahan yang lebih kompleks. Kernel ini adalah pilihan umum dalam SVM karena kemampuannya untuk menangkap hubungan non-linear.

### Model Development dengan Random Forest
"""

# Impor library yang dibutuhkan
from sklearn.ensemble import RandomForestRegressor

# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""- RandomForestRegressor dengan parameter sebagai berikut:

  - n_estimators=50: Menentukan jumlah pohon keputusan (trees) dalam hutan (forest). Semakin banyak pohon yang digunakan, model biasanya akan lebih kuat dan lebih robust, meskipun waktu pelatihan dan prediksi akan meningkat.

  - max_depth=16: Menentukan kedalaman maksimum setiap pohon dalam hutan. Ini digunakan untuk menghindari overfitting. Semakin dalam pohon, semakin banyak informasi yang dapat dipelajari, tetapi juga meningkatkan risiko model terlalu kompleks.

  - random_state=55: Parameter ini digunakan untuk memastikan reproduktifitas hasil. Dengan mengatur random_state, Anda akan mendapatkan hasil yang sama setiap kali Anda menjalankan kode.

  - n_jobs=-1: Menentukan jumlah inti (cores) yang digunakan untuk menghitung. Jika diatur ke -1, model akan menggunakan semua inti yang tersedia, sehingga mempercepat proses pelatihan.

### Model Development dengan AdaBoostRegressor
"""

from sklearn.ensemble import AdaBoostRegressor

boosting_RF = AdaBoostRegressor(estimator= RF, learning_rate=0.05, random_state=55)
boosting_RF.fit(X_train, y_train)

models.loc['train_mse','boosting_RF'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""- AdaBoostRegressor dengan parameter sebagai berikut:

  - estimator =  RF Menentukan model dasar yang digunakan sebagai estimator. Dalam hal ini, model dasar yang digunakan adalah RandomForestRegressor (yang telah didefinisikan sebelumnya dengan nama RF).

  - learning_rate = 0.05 Parameter ini mengontrol kontribusi setiap estimator ke model akhir. Dalam hal ini, learning rate diatur menjadi 0.05.

  - random_state = 55 Parameter ini digunakan untuk memastikan bahwa hasil dapat direproduksi. Dengan menetapkan nilai acak, Anda akan mendapatkan hasil yang sama setiap kali Anda

## Evaluasi Model
"""

X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

mse = pd.DataFrame(columns=['train', 'test'], index=['DecisionTree', 'KNN', 'LinearRegression', 'SVR', 'RF', 'boosting_RF'])

model_dict = {'KNN': knn, 'DecisionTree': dt_regressor, 'LinearRegression': linear_regressor, 'SVR': svr, 'RF':RF, 'boosting_RF':boosting_RF}

for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi = X_test.iloc[:5].copy()
pred_dict = {'y_true':y_test[:5]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Dari tabel di atas, dapat dilihat bahwa setiap model menghasilkan prediksi yang bervariasi untuk setiap nilai aktual (y_true). Model K-Nearest Neighbor (KNN) dan Decision Tree memberikan prediksi yang cukup dekat dengan nilai aktual pada beberapa data, sementara Linear Regression dan Random Forest juga menunjukkan hasil yang kompetitif. Model AdaBoost dengan Random Forest (boosting_RF) tampaknya menghasilkan prediksi yang lebih konsisten, dengan kesalahan relatif yang lebih kecil pada nilai prediksi dibandingkan dengan beberapa model lainnya. Secara keseluruhan, performa model dapat bervariasi tergantung pada karakteristik data dan hubungan yang ada antara fitur dan target."""